I"ÿ<p>This blog is about the <strong>‚ÄúGoogle IT Support Professional Certificate‚Äù</strong> which is available in <a href="https://www.coursera.org/professional-certificates/google-it-support">Coursera</a>. There are 5 Courses in this Professional Certificate.</p>
<ul>
  <li><a href="https://www.coursera.org/learn/technical-support-fundamentals?specialization=google-it-support">Technical Support Fundamentals</a></li>
  <li><a href="https://www.coursera.org/learn/computer-networking?specialization=google-it-support">The Bits and Bytes of Computer Networking</a></li>
  <li><a href="https://www.coursera.org/learn/os-power-user?specialization=google-it-support">Operating Systems and You: Becoming a Power User</a></li>
  <li><a href="https://www.coursera.org/learn/system-administration-it-infrastructure-services?specialization=google-it-support">System Administration and IT Infrastructure Services</a></li>
  <li><a href="https://www.coursera.org/learn/it-security?specialization=google-it-support">IT Secuirty: Defense against the digital dark arts</a></li>
</ul>
<hr style="height:2px;border-width:0;color:blue;background-color:blue" />

<p>This program prepares me for the <a href="https://www.comptia.org/certifications/a">CompTIA A+</a> exams. This blog is about the first course <a href="https://www.coursera.org/learn/technical-support-fundamentals?specialization=google-it-support">Technical Support Fundamentals</a> and summarizes the things I found useful.</p>
<hr style="height:2px;border-width:0;color:blue;background-color:blue" />

<h1 id="week-1-introduction-to-it">Week 1: Introduction to IT</h1>

<ul>
  <li>What is IT?</li>
  <li>What does an IT Support Specialist do?</li>
</ul>

<h2 id="history-of-computing">History of Computing</h2>

<ul>
  <li><strong>From Abacus to Analytical Engine</strong>
    <ul>
      <li>It is believed that the design for the QWERTY keyboard is to slow down the typist so that they wouldn‚Äôt jam old mechanical typewriters</li>
      <li>The first major step forward was the invention of the mechanical calculator in the 17th by Blaise Pascal</li>
      <li>In the 1800s, a man by the name of Joseph Jacquard invented a programmable loom‚Ä¶.looms were used in textile industry to weave yarn into fabric</li>
      <li>Charles Babbage created the Analytical Engine</li>
      <li>Ada Lovelace (She) created the first algorithm for the engine</li>
    </ul>
  </li>
  <li><strong>The Path to Modern Computers</strong>
    <ul>
      <li>War gave birth to cryptography</li>
      <li>Enigma: Alan Turing, an English Mathematician and now famous computer scientist created it which helped Allied Force decode Axis message during World War II</li>
      <li>The ENIAC was one of the earliest forms of general purpose computers. It was a wall-to-wall convolution of massive electronic components and wires. It had 17,000 vacuum tubes and took up about 1,800 square feet of floor space</li>
      <li>The very first compiler was invented by Admiral Grace Hopper. Compilers made it possible to translate human language via a programming language into machine code</li>
      <li>The Xerox Alto was the first computer that resembled the computers we‚Äôre familiar with now. It was also the first computer to implement a graphical user interface that used icons, a mouse, and a window</li>
      <li>Then in the 1970s, a young engineer named Steve Wozniak invented the Apple I, a single-board computer MIT for hobbyists. With his friend Steve Jobs, they created a company called Apple Computer</li>
      <li>In the 1980s, IBM introduced its personal computer. It was released with a primitive version of an operating system called MS DOS or Microsoft Disk Operating System.</li>
      <li>A company called Atari developed one of the first coin-operated arcade games in 1972 called Pong</li>
      <li>With huge players in the market like Apple Macintosh and Microsoft Windows taking over the operating systems space, a programmer by the name of Richard Stallman started developing a free Unix-like operating system. Unix was an operating system developed by Ken Thompson and Dennis Ritchie, but it wasn‚Äôt cheap and wasn‚Äôt available to everyone. Stallman created an OS that he called GNU. It was meant to be free to use with similar functionality to Unix.</li>
      <li>Linux, which was created by Linus Torvalds</li>
      <li>In the late 1990s, Nokia introduced a PDA with mobile phone functionality</li>
    </ul>
  </li>
</ul>

<h2 id="digital-logic">Digital Logic</h2>

<ul>
  <li><strong>Computer Languages</strong>
    <ul>
      <li>a group of 8 bits is referred to as a byte. So a byte of zeros and ones could look like 10011011. Each byte can store one character, and we can have 256 possible values, thanks to the base-2 system, 2 to the 8th</li>
    </ul>
  </li>
  <li><strong>Character Encoding</strong>
    <ul>
      <li>Character encoding is used to assign our binary values to characters so that we as humans can read them</li>
      <li>The oldest character encoding standard used this ASCII. It represents the English alphabet, digits, and punctuation marks. The first character in ASCII to binary table, a lowercase a, maps to 0 1 1 0 0 0 0 1 in binary</li>
      <li>The great thing with ASCII was that we only needed to use 127 values out of our possible 256</li>
      <li>It lasted for a very long time, but eventually it wasn‚Äôt enough. Other character encoding standards recreated to represent different languages, different amounts of characters and more. Eventually they would require more than 256 values we were allowed to have. Then came UTF8</li>
    </ul>
  </li>
  <li><strong>Supplemental Reading on <a href="https://simple.wikipedia.org/wiki/Logic_gate">Logic gate</a></strong></li>
  <li><strong>Binary</strong>
    <ul>
      <li>128, 64, 32, 16, 8, 4, 2, 1 and the sum is 255</li>
    </ul>
  </li>
  <li><strong>Computer Architecture Layer</strong>
    <ul>
      <li>Abstraction
        <ul>
          <li>Abstraction hides complexity by providing a common interface, the steering wheel, pedals, gear stick, and gauges in our car example</li>
          <li>In computing, we use abstraction to make a very complex problem, like how to make computers work, easier to think about. We do that by breaking it apart into simpler ideas that describe single concepts or individual jobs that need to be done, and then stack them in layers</li>
          <li>One other simple example of abstraction in an IT role that you might see a lot is an error message. We don‚Äôt have to dig through someone else‚Äôs code and find a bug. This has been abstracted out for us already in the form of an error message. A simple error message like file not found actually tells us a lot of information and saves us time to figure out a solution</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

:ET